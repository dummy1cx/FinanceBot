{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact final_chatbot_checkpoint:v0, 288.27MB. 2 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "Done. 0:0:1.3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary packages for inference\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from utils import Voc\n",
    "from dataset import loadPrepareData, trimRareWords, split_dataset, get_dataloader\n",
    "from model import EncoderRNN, LuongAttnDecoderRNN\n",
    "from evaluate import GreedySearchDecoder\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "from dataset import *\n",
    "from model import *\n",
    "from evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact final_chatbot_checkpoint:v0, 288.27MB. 2 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "Done. 0:0:1.4\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "import torch\n",
    "wandb.init()\n",
    "\n",
    "\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "artifact = wandb.use_artifact(\"abhi1199-city-university-of-london/seq2seqRNNXAtten_last/final_chatbot_checkpoint:v0\", type=\"model\")\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "checkpoint_path = os.path.join(artifact_dir, \"final_checkpoint.tar\")\n",
    "voc_path = os.path.join(artifact_dir, \"voc.pkl\")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(voc_path, \"rb\") as f:\n",
    "    voc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Financeot is ready to solve your query! Type 'quit' to exit.\n",
      "Bot: some you can have a successful mobile of parts a test that can help you as much as possible . .\n",
      "Bot: i believe you believe and what you have that can have you been . it is always good to have have you to have . .\n",
      "Bot: there are three players you need to take a few steps . .\n",
      "Bot: the criteria for you for is as follows as of and and and and . and .\n",
      "Bot: it is not a common step to make it easy to pay . you are here to you pay about your money . you you you .\n"
     ]
    }
   ],
   "source": [
    "# model configuration for inferecne\n",
    "hidden_size = checkpoint['embedding_state']['weight'].shape[1]\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(checkpoint['embedding_state'])\n",
    "embedding = embedding.to(device)\n",
    "\n",
    "encoder = EncoderRNN(hidden_size, embedding, n_layers=2, dropout=0.1).to(device)\n",
    "decoder = LuongAttnDecoderRNN(\"dot\", embedding, hidden_size, voc.num_words, n_layers=2, dropout=0.1).to(device)\n",
    "\n",
    "encoder.load_state_dict(checkpoint['encoder_state'])\n",
    "decoder.load_state_dict(checkpoint['decoder_state'])\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize GreedySearchDecoder\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Chat loop\n",
    "def chat():\n",
    "    print(\"Hello! Financeot is ready to solve your query! Type 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            input_sentence = input(\"> \")\n",
    "            if input_sentence.lower() in [\"quit\", \"q\"]:\n",
    "                break\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            output_words = [w for w in output_words if w not in [\"EOS\", \"PAD\"]]\n",
    "            print(\"Bot:\", ' '.join(output_words))\n",
    "        except KeyError:\n",
    "            print(\"Oops! Encountered unknown word. Try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Financeot is ready to solve your query! Type 'quit' to exit.\n",
      "You: Why do some stocks have a higher margin requirement?\n",
      "Bot: some you can have a successful mobile of parts a test that can help you as much as possible . .\n",
      "You: why do I need an emergency fund if I already have investments?\n",
      "Bot: i believe you believe and what you have that can have you been . it is always good to have have you to have . .\n",
      "You: How would bonds fare if interest rates rose?\n",
      "Bot: there are three players you need to take a few steps . .\n",
      "You: Is it possible to make money by getting a mortgage?\n",
      "Bot: it is not a common step to make it easy to pay . you are here to you pay about your money . you you you .\n",
      "You: What can cause rent prices to fall?\n",
      "Bot: . have a comprehensive type of reasons to the task or open a few situation . . . .\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    print(\"Hello! Financeot is ready to solve your query! Type 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            input_sentence = input(\"> \")\n",
    "            if input_sentence.lower() in [\"quit\", \"q\"]:\n",
    "                break\n",
    "            print(\"You:\", input_sentence)  # ðŸ‘ˆ this line makes it visible\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            output_words = [w for w in output_words if w not in [\"EOS\", \"PAD\"]]\n",
    "            print(\"Bot:\", ' '.join(output_words))\n",
    "        except KeyError:\n",
    "            print(\"Oops! Encountered unknown word. Try again.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
